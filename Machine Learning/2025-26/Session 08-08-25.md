# Session of Machine Learning Division of CyberLabs
Conducted on: 08/08/2025

## Agenda
MobileNet v1 and Squeeze-and-Excitation Network

## Summary
1. Introduction to MobileNet v1 and its motivation for building lightweight and efficient convolutional neural networks.
2. Overview of the MobileNet v1 architecture and its layer-wise design.
3. Explanation of Depthwise Separable Convolutions and how they differ from standard convolutions.
4. ⁠Discussion on the reduction of computational cost and number of parameters using depthwise and pointwise convolutions.
5. ⁠Detailed discussion on the Width Multiplier  used to scale the number of channels in the network.
6. ⁠Explanation of the Resolution Multiplier and its role in reducing input feature map resolution.
7. ⁠Discussion on how width and resolution multipliers help in controlling the trade-off between accuracy and efficiency.
8. ⁠Detailed discussion on the Squeeze operation using global average pooling to capture channel-wise statistics.
9. ⁠Explanation of the Excitation operation, where learned weights are used for channel re-weighting.
10. Discussion on how SE blocks can be integrated into existing CNN architectures.
11. Analysis of how the Squeeze-and-Excitation mechanism resembles attention mechanisms by emphasizing informative channels and suppressing less useful ones.


## Agenda for the next session
* MobileNet v2
* U-Net
* EfficientNet


## Report Compiled by
Ritesh Kumbhare

## Attendees
3rd year: Harshvardhan Sir, Mukil Sir, Dilshad Sir.

2nd year: Anab, Arnav, Arjav Anukul, Abhishek, Ritesh, Rajat, Sreenandan, Ayushman.

## Absentees
Second Year: None
